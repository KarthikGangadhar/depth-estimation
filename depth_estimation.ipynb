{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jDk7XD7ofSnZ"
      },
      "outputs": [],
      "source": [
        "!wget -cq https://s3-eu-west-1.amazonaws.com/densedepth/nyu_test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4YS1XPM-gr7e"
      },
      "outputs": [],
      "source": [
        "!wget -cq https://s3-eu-west-1.amazonaws.com/densedepth/nyu_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "colab_type": "code",
        "id": "Y9x-x1Z2g05d",
        "outputId": "adde40a4-fbe4-485f-d09d-087afeaec183"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from keras.engine.topology import Layer, InputSpec\n",
        "import keras.utils.conv_utils as conv_utils\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "# These are debugger layers\n",
        "class BilinearUpSampling2D(Layer):\n",
        "    def __init__(self, size=(2, 2), data_format=None, **kwargs):\n",
        "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
        "        self.data_format = K.normalize_data_format(data_format)\n",
        "        self.size = conv_utils.normalize_tuple(size, 2, 'size')\n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n",
        "            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n",
        "            return (input_shape[0],\n",
        "                    input_shape[1],\n",
        "                    height,\n",
        "                    width)\n",
        "        elif self.data_format == 'channels_last':\n",
        "            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n",
        "            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n",
        "            return (input_shape[0],\n",
        "                    height,\n",
        "                    width,\n",
        "                    input_shape[3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = K.shape(inputs)\n",
        "        if self.data_format == 'channels_first':\n",
        "            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n",
        "            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n",
        "        elif self.data_format == 'channels_last':\n",
        "            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n",
        "            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n",
        "        \n",
        "        return tf.image.resize_images(inputs, [height, width], method=tf.image.ResizeMethod.BILINEAR, align_corners=True)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'size': self.size, 'data_format': self.data_format}\n",
        "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Non-random random\n",
        "random.seed(0)\n",
        "\n",
        "class BasicPolicy(object):\n",
        "    def __init__(self, mirror_ratio = 0, flip_ratio = 0, color_change_ratio = 0, is_full_set_colors = False, add_noise_peak = 0.0, erase_ratio = -1.0):\n",
        "        # Random color channel order\n",
        "        from itertools import product, permutations\n",
        "        self.indices = list(product([0,1,2], repeat = 3)) if is_full_set_colors else list(permutations(range(3), 3))\n",
        "        self.indices.insert(0, [0,1,2]) # R,G,B\n",
        "        self.add_noise_peak = add_noise_peak\n",
        "\n",
        "        # Mirror and flip\n",
        "        self.color_change_ratio = color_change_ratio\n",
        "        self.mirror_ratio = mirror_ratio\n",
        "        self.flip_ratio = flip_ratio\n",
        "\n",
        "        # Erase\n",
        "        self.erase_ratio = erase_ratio\n",
        "\n",
        "    def __call__(self, img, depth):\n",
        "\n",
        "        # 0) Add poisson noise (e.g. choose peak value 20)\n",
        "        # https://stackoverflow.com/questions/19289470/adding-poisson-noise-to-an-image\n",
        "        if self.add_noise_peak > 0:\n",
        "            PEAK = self.add_noise_peak\n",
        "            img = np.random.poisson(np.clip(img, 0, 1) * PEAK) / PEAK\n",
        "\n",
        "        # 1) Color change\n",
        "        policy_idx = random.randint(0, len(self.indices) - 1)\n",
        "        if random.uniform(0, 1) >= self.color_change_ratio:\n",
        "            policy_idx = 0\n",
        "\n",
        "        img = img[...,list(self.indices[policy_idx])]\n",
        "\n",
        "        # 2) Mirror image\n",
        "        if random.uniform(0, 1) <= self.mirror_ratio:\n",
        "            img = img[...,::-1,:]\n",
        "            depth = depth[...,::-1,:]\n",
        "\n",
        "        # 3) Flip image vertically\n",
        "        if random.uniform(0, 1) < self.flip_ratio:\n",
        "            img = img[...,::-1,:,:]\n",
        "            depth = depth[...,::-1,:,:]\n",
        "\n",
        "        # 4) Erase random box\n",
        "        if random.uniform(0, 1) < self.erase_ratio:\n",
        "            img = self.eraser(img)\n",
        "\n",
        "        return img, depth\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Basic Policy\"\n",
        "\n",
        "    def eraser(self, input_img, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=True):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "        \n",
        "    def debug_img(self, img, depth, idx, i, prefix=''):\n",
        "        from PIL import Image\n",
        "        aug_img = Image.fromarray(np.clip(np.uint8(img*255), 0, 255))\n",
        "        aug_img.save(prefix+str(idx)+\"_\"+str(i)+'.jpg',quality=99)\n",
        "        aug_img = Image.fromarray(np.clip(np.uint8(np.tile(depth*255,3)), 0, 255))\n",
        "        aug_img.save(prefix+str(idx)+\"_\"+str(i)+'.depth.jpg',quality=99)\n",
        "\n",
        "#\n",
        "# Original code at https://github.com/DeepVoltaire/AutoAugment\n",
        "#\n",
        "class ImageNetPolicy(object):\n",
        "    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n",
        "\n",
        "        Example:\n",
        "        >>> policy = ImageNetPolicy()\n",
        "        >>> transformed = policy(image)\n",
        "\n",
        "        Example as a PyTorch Transform:\n",
        "        >>> transform=transforms.Compose([\n",
        "        >>>     transforms.Resize(256),\n",
        "        >>>     ImageNetPolicy(),\n",
        "        >>>     transforms.ToTensor()])\n",
        "    \"\"\"\n",
        "    def __init__(self, fillcolor=(128, 128, 128)):\n",
        "        self.policies = [\n",
        "            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n",
        "            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n",
        "            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n",
        "            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n",
        "\n",
        "            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n",
        "            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n",
        "            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n",
        "\n",
        "            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n",
        "            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n",
        "            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n",
        "\n",
        "            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n",
        "            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n",
        "            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n",
        "            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n",
        "\n",
        "            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n",
        "            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n",
        "            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n",
        "            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
        "        return self.policies[policy_idx](img)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"AutoAugment ImageNet Policy\"\n",
        "\n",
        "# This is data augmentaion part\n",
        "class SubPolicy(object):\n",
        "    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n",
        "        ranges = {\n",
        "            \"shearX\": np.linspace(0, 0.3, 10),\n",
        "            \"shearY\": np.linspace(0, 0.3, 10),\n",
        "            \"translateX\": np.linspace(0, 150 / 331, 10),\n",
        "            \"translateY\": np.linspace(0, 150 / 331, 10),\n",
        "            \"rotate\": np.linspace(0, 30, 10),\n",
        "            \"color\": np.linspace(0.0, 0.9, 10),\n",
        "            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n",
        "            \"solarize\": np.linspace(256, 0, 10),\n",
        "            \"contrast\": np.linspace(0.0, 0.9, 10),\n",
        "            \"sharpness\": np.linspace(0.0, 0.9, 10),\n",
        "            \"brightness\": np.linspace(0.0, 0.9, 10),\n",
        "            \"autocontrast\": [0] * 10,\n",
        "            \"equalize\": [0] * 10,\n",
        "            \"invert\": [0] * 10\n",
        "        }\n",
        "\n",
        "        # from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n",
        "        def rotate_with_fill(img, magnitude):\n",
        "            rot = img.convert(\"RGBA\").rotate(magnitude)\n",
        "            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n",
        "\n",
        "        func = {\n",
        "            \"shearX\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n",
        "                Image.BICUBIC, fillcolor=fillcolor),\n",
        "            \"shearY\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n",
        "                Image.BICUBIC, fillcolor=fillcolor),\n",
        "            \"translateX\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n",
        "                fillcolor=fillcolor),\n",
        "            \"translateY\": lambda img, magnitude: img.transform(\n",
        "                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n",
        "                fillcolor=fillcolor),\n",
        "            #\"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n",
        "            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n",
        "\t\t\t\"rotate\": lambda img, magnitude: img,\n",
        "            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n",
        "            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n",
        "            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n",
        "            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n",
        "                1 + magnitude * random.choice([-1, 1])),\n",
        "            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n",
        "            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n",
        "            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n",
        "        }\n",
        "\n",
        "        # self.name = \"{}_{:.2f}_and_{}_{:.2f}\".format(\n",
        "        #     operation1, ranges[operation1][magnitude_idx1],\n",
        "        #     operation2, ranges[operation2][magnitude_idx2])\n",
        "        self.p1 = p1\n",
        "        self.operation1 = func[operation1]\n",
        "        self.magnitude1 = ranges[operation1][magnitude_idx1]\n",
        "        self.p2 = p2\n",
        "        self.operation2 = func[operation2]\n",
        "        self.magnitude2 = ranges[operation2][magnitude_idx2]\n",
        "\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n",
        "        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n",
        "        return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UVvG08iShqe2"
      },
      "outputs": [],
      "source": [
        "\"\"\"This contains main data handling methods, all are needed\"\"\"\n",
        "\n",
        "import io\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# from helpers import DepthNorm\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "from keras.utils import Sequence\n",
        "#from helpers import BasicPolicy\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def DepthNorm(x, maxDepth):\n",
        "    return maxDepth / x\n",
        "\n",
        "def scale_up(scale, images):\n",
        "    from skimage.transform import resize\n",
        "    scaled = []\n",
        "    \n",
        "    for i in range(len(images)):\n",
        "        img = images[i]\n",
        "        output_shape = (scale * img.shape[0], scale * img.shape[1])\n",
        "        scaled.append( resize(img, output_shape, order=1, preserve_range=True, mode='reflect', anti_aliasing=True ) )\n",
        "\n",
        "    return np.stack(scaled)\n",
        "\n",
        "def predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\n",
        "    # Support multiple RGBs, one RGB image, even grayscale \n",
        "    if len(images.shape) < 3: images = np.stack((images,images,images), axis=2)\n",
        "    if len(images.shape) < 4: images = images.reshape((1, images.shape[0], images.shape[1], images.shape[2]))\n",
        "    # Compute predictions\n",
        "    predictions = model.predict(images, batch_size=batch_size)\n",
        "    # Put in expected range\n",
        "    return np.clip(DepthNorm(predictions, maxDepth=1000), minDepth, maxDepth) / maxDepth\n",
        "\n",
        "def load_test_data(test_data_zip_file='nyu_test.zip'):\n",
        "    print('Loading test data...', end='')\n",
        "    import numpy as np\n",
        "    from data import extract_zip\n",
        "    data = extract_zip(test_data_zip_file)\n",
        "    from io import BytesIO\n",
        "    rgb = np.load(BytesIO(data['eigen_test_rgb.npy']))\n",
        "    depth = np.load(BytesIO(data['eigen_test_depth.npy']))\n",
        "    crop = np.load(BytesIO(data['eigen_test_crop.npy']))\n",
        "    print('Test data loaded.\\n')\n",
        "    return {'rgb':rgb, 'depth':depth, 'crop':crop}\n",
        "\n",
        "def evaluate(model, rgb, depth, crop, batch_size=6, verbose=True):\n",
        "    # Error computaiton based on https://github.com/tinghuiz/SfMLearner\n",
        "    def compute_errors(gt, pred):\n",
        "        thresh = np.maximum((gt / pred), (pred / gt))\n",
        "        \n",
        "        a1 = (thresh < 1.25   ).mean()\n",
        "        a2 = (thresh < 1.25 ** 2).mean()\n",
        "        a3 = (thresh < 1.25 ** 3).mean()\n",
        "\n",
        "        abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
        "\n",
        "        rmse = (gt - pred) ** 2\n",
        "        rmse = np.sqrt(rmse.mean())\n",
        "\n",
        "        log_10 = (np.abs(np.log10(gt)-np.log10(pred))).mean()\n",
        "\n",
        "        return a1, a2, a3, abs_rel, rmse, log_10\n",
        "\n",
        "    depth_scores = np.zeros((6, len(rgb))) # six metrics\n",
        "\n",
        "    bs = batch_size\n",
        "\n",
        "    for i in range(len(rgb)//bs):    \n",
        "        x = rgb[(i)*bs:(i+1)*bs,:,:,:]\n",
        "        \n",
        "        # Compute results\n",
        "        true_y = depth[(i)*bs:(i+1)*bs,:,:]\n",
        "        pred_y = scale_up(2, predict(model, x/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "        \n",
        "        # Test time augmentation: mirror image estimate\n",
        "        pred_y_flip = scale_up(2, predict(model, x[...,::-1,:]/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "\n",
        "        # Crop based on Eigen et al. crop\n",
        "        true_y = true_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y = pred_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y_flip = pred_y_flip[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        \n",
        "        # Compute errors per image in batch\n",
        "        for j in range(len(true_y)):\n",
        "            errors = compute_errors(true_y[j], (0.5 * pred_y[j]) + (0.5 * np.fliplr(pred_y_flip[j])))\n",
        "            \n",
        "            for k in range(len(errors)):\n",
        "                depth_scores[k][(i*bs)+j] = errors[k]\n",
        "\n",
        "    e = depth_scores.mean(axis=1)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
        "        print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))\n",
        "\n",
        "    return e\n",
        "\n",
        "def depth_loss_function(y_true, y_pred, theta=0.1, maxDepthVal=1000.0/10.0):\n",
        "    \n",
        "    # Point-wise depth\n",
        "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
        "\n",
        "    # Edges\n",
        "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
        "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
        "    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
        "\n",
        "    # Structural similarity (SSIM) index\n",
        "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n",
        "\n",
        "    # Weights\n",
        "    w1 = 1.0\n",
        "    w2 = 1.0\n",
        "    w3 = theta\n",
        "\n",
        "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))\n",
        "    \n",
        "def extract_zip(input_zip):\n",
        "    input_zip=ZipFile(input_zip)\n",
        "    return {name: input_zip.read(name) for name in input_zip.namelist()}\n",
        "\n",
        "def nyu_resize(img, resolution=480, padding=6):\n",
        "    from skimage.transform import resize\n",
        "    return resize(img, (resolution, int(resolution*4/3)), preserve_range=True, mode='reflect', anti_aliasing=True )\n",
        "\n",
        "def get_nyu_data(batch_size, nyu_data_zipfile='nyu_data.zip'):\n",
        "    data = extract_zip(nyu_data_zipfile)\n",
        "\n",
        "    nyu2_train = list((row.strip().split(',') for row in (data['data/nyu2_train.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\n",
        "    nyu2_test = list((row.strip().split(',') for row in (data['data/nyu2_test.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\n",
        "\n",
        "    shape_rgb = (batch_size, 480, 640, 3)\n",
        "    shape_depth = (batch_size, 240, 320, 1)\n",
        "\n",
        "    return data, nyu2_train, nyu2_test, shape_rgb, shape_depth\n",
        "\n",
        "def get_nyu_train_test_data(batch_size):\n",
        "    data, nyu2_train, nyu2_test, shape_rgb, shape_depth = get_nyu_data(batch_size)\n",
        "\n",
        "    train_generator = NYU_BasicAugmentRGBSequence(data, nyu2_train, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\n",
        "    test_generator = NYU_BasicRGBSequence(data, nyu2_test, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\n",
        "\n",
        "    return train_generator, test_generator\n",
        "\n",
        "class NYU_BasicAugmentRGBSequence(Sequence):\n",
        "    def __init__(self, data, dataset, batch_size, shape_rgb, shape_depth, is_flip=False, is_addnoise=False, is_erase=False):\n",
        "        self.data = data\n",
        "        self.dataset = dataset\n",
        "        self.policy = BasicPolicy( color_change_ratio=0.50, mirror_ratio=0.50, flip_ratio=0.0 if not is_flip else 0.2, \n",
        "                                    add_noise_peak=0 if not is_addnoise else 20, erase_ratio=-1.0 if not is_erase else 0.5)\n",
        "        self.batch_size = batch_size\n",
        "        self.shape_rgb = shape_rgb\n",
        "        self.shape_depth = shape_depth\n",
        "        self.maxDepth = 1000.0\n",
        "\n",
        "        from sklearn.utils import shuffle\n",
        "        self.dataset = shuffle(self.dataset, random_state=0)\n",
        "\n",
        "        self.N = len(self.dataset)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.N / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx, is_apply_policy=True):\n",
        "        batch_x, batch_y = np.zeros( self.shape_rgb ), np.zeros( self.shape_depth )\n",
        "\n",
        "        # Augmentation of RGB images\n",
        "        for i in range(batch_x.shape[0]):\n",
        "            index = min((idx * self.batch_size) + i, self.N-1)\n",
        "\n",
        "            sample = self.dataset[index]\n",
        "\n",
        "            x = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[0]]) )).reshape(480,640,3)/255,0,1)\n",
        "            y = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[1]]) )).reshape(480,640,1)/255*self.maxDepth,0,self.maxDepth)\n",
        "            y = DepthNorm(y, maxDepth=self.maxDepth)\n",
        "\n",
        "            batch_x[i] = nyu_resize(x, 480)\n",
        "            batch_y[i] = nyu_resize(y, 240)\n",
        "\n",
        "            if is_apply_policy: batch_x[i], batch_y[i] = self.policy(batch_x[i], batch_y[i])\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "class NYU_BasicRGBSequence(Sequence):\n",
        "    def __init__(self, data, dataset, batch_size,shape_rgb, shape_depth):\n",
        "        self.data = data\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.N = len(self.dataset)\n",
        "        self.shape_rgb = shape_rgb\n",
        "        self.shape_depth = shape_depth\n",
        "        self.maxDepth = 1000.0\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.N / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x, batch_y = np.zeros( self.shape_rgb ), np.zeros( self.shape_depth )\n",
        "        for i in range(self.batch_size):            \n",
        "            index = min((idx * self.batch_size) + i, self.N-1)\n",
        "\n",
        "            sample = self.dataset[index]\n",
        "\n",
        "            x = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[0]]))).reshape(480,640,3)/255,0,1)\n",
        "            y = np.asarray(Image.open(BytesIO(self.data[sample[1]])), dtype=np.float32).reshape(480,640,1).copy().astype(float) / 10.0\n",
        "            y = DepthNorm(y, maxDepth=self.maxDepth)\n",
        "\n",
        "            batch_x[i] = nyu_resize(x, 480)\n",
        "            batch_y[i] = nyu_resize(y, 240)\n",
        "\n",
        "            # DEBUG:\n",
        "            #self.policy.debug_img(batch_x[i], np.clip(DepthNorm(batch_y[i])/maxDepth,0,1), idx, i)\n",
        "        #exit()\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "def load_test_data(test_data_zip_file='nyu_test.zip'):\n",
        "    print('Loading test data...', end='')\n",
        "    import numpy as np\n",
        "    from data import extract_zip\n",
        "    data = extract_zip(test_data_zip_file)\n",
        "    from io import BytesIO\n",
        "    rgb = np.load(BytesIO(data['eigen_test_rgb.npy']))\n",
        "    depth = np.load(BytesIO(data['eigen_test_depth.npy']))\n",
        "    crop = np.load(BytesIO(data['eigen_test_crop.npy']))\n",
        "    print('Test data loaded.\\n')\n",
        "    return {'rgb':rgb, 'depth':depth, 'crop':crop}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "DCOOKCogh0VV",
        "outputId": "8e9baad6-19c4-4014-f72c-0c066c2a2dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch_size = 5 , epochs = 5, lr = 0.0001\n",
            "Loading base model (UNet)..\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 6 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 6 36928       conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 1 73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 1 147584      conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 2 295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 2 590080      conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 5 1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 5 2359808     conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, None, 5 0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 5 0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 1 4719616     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 1 9438208     conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, None, 1 0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, None, None, 1 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 5 2097664     up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 1 0           dropout_1[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 5 4719104     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 5 2359808     conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, None, None, 5 0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 2 524544      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 5 0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 2 1179904     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 2 590080      conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, None, None, 2 0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 1 131200      up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, None, None, 2 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 1 295040      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 1 147584      conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 1 129         conv2d_19[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 30,888,257\n",
            "Trainable params: 30,888,257\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "(?, ?, ?, 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output: /content/models/1575915587\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Ready for training!\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "10138/10138 [==============================] - 6801s 671ms/step - loss: 0.2510 - val_loss: 0.2255\n",
            "Epoch 2/5\n",
            "10138/10138 [==============================] - 6785s 669ms/step - loss: 0.2083 - val_loss: 0.2177\n",
            "Epoch 3/5\n",
            " 7630/10138 [=====================>........] - ETA: 27:42 - loss: 0.1756"
          ]
        }
      ],
      "source": [
        "import os, sys, glob, time, pathlib\n",
        "\n",
        "from keras import applications\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, InputLayer, Conv2D, Activation, LeakyReLU, Concatenate, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def create_model():\n",
        "    \n",
        "    print('Loading base model (UNet)..')\n",
        "    inputs = Input(shape=(None, None, 3))\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    conv10 = Conv2D(1, 1)(conv8)\n",
        "\n",
        "    model = Model(input = inputs, output = conv10)\n",
        "    model.summary()\n",
        "    print(model.layers[-1].output.shape)\n",
        "    return model\n",
        "\n",
        "def train(batch_size = 5 , epochs = 5, lr = 0.0001):\n",
        "    print(\"batch_size = {0} , epochs = {1}, lr = {2}\".format(batch_size,epochs, lr))\n",
        "\n",
        "    #creates encoder and decoder model\n",
        "    model = create_model()\n",
        "\n",
        "    train_generator, test_generator = get_nyu_train_test_data( batch_size )\n",
        "\n",
        "    # Training session details\n",
        "    runPath = os.path.join(os.getcwd(),'models',str(int(time.time())))\n",
        "    pathlib.Path(runPath).mkdir(parents=True, exist_ok=True)\n",
        "    print('Output: ' + runPath)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = Adam(lr=lr, amsgrad=True)\n",
        "\n",
        "    model.compile(loss=depth_loss_function, optimizer=optimizer)\n",
        "\n",
        "    # Start training\n",
        "    model.fit_generator(train_generator, callbacks=None, validation_data=test_generator, epochs=epochs, shuffle=True)\n",
        "\n",
        "    # Save the final trained model:\n",
        "    print('Model Save Began')\n",
        "    model.save(runPath + '/unetmodel.h5')\n",
        "    print('Model Save Completed')\n",
        "    pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = sys.argv[ 1: ]\n",
        "    if (len(args) <= 0) :\n",
        "        sys.exit( 0 )\n",
        "    \n",
        "    batch_size= 5 \n",
        "    epochs= 5 \n",
        "    lr= 0.0001\n",
        "    train( batch_size, epochs, lr)\n"
      ]
    }
  ]
}