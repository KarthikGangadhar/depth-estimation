{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalProjectlatest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk2HP-JxnlfV",
        "colab_type": "text"
      },
      "source": [
        "Mahin's Dataset"
      ]
    },
    {
      "source": [
        "# !wget -cq https://4yz2la.bn.files.1drv.com/y4mhrJT1X2DBj1ZXaPXCoQkkS6WwzAz_XdJDUIh_9rnt63MLJ5yy6SC23bu64NmKPripJYlHV665FGnwBxAq-1lv9VCafC0E6obLlCt_-saXYwTB13fVNiQPrUT2JZYBON1rIXRXnvnICoT7jroyS-gKBDrhxhL67FtWSC9VivIgrfn2vSeibd9ETBNypd9njplOOKRNCtG3Bpgz5Z_Ysq1YFEfCUQ5QZajU75hJp7CqDQ/nyu_data.zip"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "evalue": "Error: Failed to connect to Jupyter notebook. \r\nhttp://localhost:8888/\r\nError: Invalid response: 500 Internal Server Error"
        }
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sk8_-henyhJ",
        "colab_type": "text"
      },
      "source": [
        "Yash's Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YavQDoT0n0dN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget -cp https://4iz2la.bn.files.1drv.com/y4mbkdtKoJnq_NBglCJJGvfrQdi3_-t48BOwi5p_lk_RA_R40AE2vZrXkhxo68LU6CXBI9Prxwle01FTupuJPexObohquqHgRiv1-oHAndwkJjPcoMaM3ALvTMn9go-BLYs7ehAb3tOfVCOnaHdGrtJcIQf8Zs6O82r4PzbbLJVWzsBF-Du_xtC3DutBA-ADiNHN2XZu1M8jOyRztXQxbNgbolbvmAfy9mbb_3WWN5SimM/nyu_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af-pa61OHf_K",
        "colab_type": "text"
      },
      "source": [
        "These two commands will download test and train dataset"
      ]
    },
    {
      "source": [
        "!wget -cq https://s3-eu-west-1.amazonaws.com/densedepth/nyu_test.zip\n"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "evalue": "Error: Failed to connect to Jupyter notebook. \r\nhttp://localhost:8888/\r\nError: Invalid response: 500 Internal Server Error"
        }
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUxc5dwNKarr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -cq https://s3-eu-west-1.amazonaws.com/densedepth/nyu_data.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urbKiYw6LSWC",
        "colab_type": "text"
      },
      "source": [
        "No Replacement for this class, its called basic policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rD2m8KMrSln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Non-random random\n",
        "random.seed(0)\n",
        "\n",
        "class BasicPolicy(object):\n",
        "    def __init__(self, mirror_ratio = 0, flip_ratio = 0, color_change_ratio = 0, is_full_set_colors = False, add_noise_peak = 0.0, erase_ratio = -1.0):\n",
        "        # Random color channel order\n",
        "        from itertools import product, permutations\n",
        "        self.indices = list(product([0,1,2], repeat = 3)) if is_full_set_colors else list(permutations(range(3), 3))\n",
        "        self.indices.insert(0, [0,1,2]) # R,G,B\n",
        "        self.add_noise_peak = add_noise_peak\n",
        "\n",
        "        # Mirror and flip\n",
        "        self.color_change_ratio = color_change_ratio\n",
        "        self.mirror_ratio = mirror_ratio\n",
        "        self.flip_ratio = flip_ratio\n",
        "\n",
        "        # Erase\n",
        "        self.erase_ratio = erase_ratio\n",
        "\n",
        "    def __call__(self, img, depth):\n",
        "\n",
        "        # 0) Add poisson noise (e.g. choose peak value 20)\n",
        "        # https://stackoverflow.com/questions/19289470/adding-poisson-noise-to-an-image\n",
        "        if self.add_noise_peak > 0:\n",
        "            PEAK = self.add_noise_peak\n",
        "            img = np.random.poisson(np.clip(img, 0, 1) * PEAK) / PEAK\n",
        "\n",
        "        # 1) Color change\n",
        "        policy_idx = random.randint(0, len(self.indices) - 1)\n",
        "        if random.uniform(0, 1) >= self.color_change_ratio:\n",
        "            policy_idx = 0\n",
        "\n",
        "        img = img[...,list(self.indices[policy_idx])]\n",
        "\n",
        "        # 2) Mirror image\n",
        "        if random.uniform(0, 1) <= self.mirror_ratio:\n",
        "            img = img[...,::-1,:]\n",
        "            depth = depth[...,::-1,:]\n",
        "\n",
        "        # 3) Flip image vertically\n",
        "        if random.uniform(0, 1) < self.flip_ratio:\n",
        "            img = img[...,::-1,:,:]\n",
        "            depth = depth[...,::-1,:,:]\n",
        "\n",
        "        # 4) Erase random box\n",
        "        if random.uniform(0, 1) < self.erase_ratio:\n",
        "            img = self.eraser(img)\n",
        "\n",
        "        return img, depth\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Basic Policy\"\n",
        "\n",
        "    def eraser(self, input_img, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=True):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "        \n",
        "    def debug_img(self, img, depth, idx, i, prefix=''):\n",
        "        from PIL import Image\n",
        "        aug_img = Image.fromarray(np.clip(np.uint8(img*255), 0, 255))\n",
        "        aug_img.save(prefix+str(idx)+\"_\"+str(i)+'.jpg',quality=99)\n",
        "        aug_img = Image.fromarray(np.clip(np.uint8(np.tile(depth*255,3)), 0, 255))\n",
        "        aug_img.save(prefix+str(idx)+\"_\"+str(i)+'.depth.jpg',quality=99)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uG8HcYKLdez",
        "colab_type": "text"
      },
      "source": [
        "This contains main data handling methods, all are needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3n1yQir7ClF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#from utils import DepthNorm\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "from keras.utils import Sequence\n",
        "#from augment import BasicPolicy\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def DepthNorm(x, maxDepth):\n",
        "    return maxDepth / x\n",
        "\n",
        "def depth_loss_function(y_true, y_pred, theta=0.1, maxDepthVal=1000.0/10.0):\n",
        "    \n",
        "    # Point-wise depth\n",
        "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
        "\n",
        "    # Edges\n",
        "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
        "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
        "    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
        "\n",
        "    # Structural similarity (SSIM) index\n",
        "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n",
        "\n",
        "    # Weights\n",
        "    w1 = 1.0\n",
        "    w2 = 1.0\n",
        "    w3 = theta\n",
        "\n",
        "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))\n",
        "    \n",
        "def extract_zip(input_zip):\n",
        "    input_zip=ZipFile(input_zip)\n",
        "    return {name: input_zip.read(name) for name in input_zip.namelist()}\n",
        "\n",
        "def nyu_resize(img, resolution=480, padding=6):\n",
        "    from skimage.transform import resize\n",
        "    return resize(img, (resolution, int(resolution*4/3)), preserve_range=True, mode='reflect', anti_aliasing=True )\n",
        "\n",
        "def get_nyu_data(batch_size, nyu_data_zipfile='nyu_data.zip'):\n",
        "    data = extract_zip(nyu_data_zipfile)\n",
        "\n",
        "    nyu2_train = list((row.strip().split(',') for row in (data['data/nyu2_train.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\n",
        "    nyu2_test = list((row.strip().split(',') for row in (data['data/nyu2_test.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\n",
        "\n",
        "    shape_rgb = (batch_size, 480, 640, 3)\n",
        "    shape_depth = (batch_size, 240, 320, 1)\n",
        "\n",
        "    return data, nyu2_train, nyu2_test, shape_rgb, shape_depth\n",
        "\n",
        "def get_nyu_train_test_data(batch_size):\n",
        "    data, nyu2_train, nyu2_test, shape_rgb, shape_depth = get_nyu_data(batch_size)\n",
        "\n",
        "    train_generator = NYU_BasicAugmentRGBSequence(data, nyu2_train, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\n",
        "    test_generator = NYU_BasicRGBSequence(data, nyu2_test, batch_size=batch_size, shape_rgb=shape_rgb, shape_depth=shape_depth)\n",
        "\n",
        "    return train_generator, test_generator\n",
        "\n",
        "class NYU_BasicAugmentRGBSequence(Sequence):\n",
        "    def __init__(self, data, dataset, batch_size, shape_rgb, shape_depth, is_flip=False, is_addnoise=False, is_erase=False):\n",
        "        self.data = data\n",
        "        self.dataset = dataset\n",
        "        self.policy = BasicPolicy( color_change_ratio=0.50, mirror_ratio=0.50, flip_ratio=0.0 if not is_flip else 0.2, \n",
        "                                    add_noise_peak=0 if not is_addnoise else 20, erase_ratio=-1.0 if not is_erase else 0.5)\n",
        "        self.batch_size = batch_size\n",
        "        self.shape_rgb = shape_rgb\n",
        "        self.shape_depth = shape_depth\n",
        "        self.maxDepth = 1000.0\n",
        "\n",
        "        from sklearn.utils import shuffle\n",
        "        self.dataset = shuffle(self.dataset, random_state=0)\n",
        "\n",
        "        self.N = len(self.dataset)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.N / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx, is_apply_policy=True):\n",
        "        batch_x, batch_y = np.zeros( self.shape_rgb ), np.zeros( self.shape_depth )\n",
        "\n",
        "        # Augmentation of RGB images\n",
        "        for i in range(batch_x.shape[0]):\n",
        "            index = min((idx * self.batch_size) + i, self.N-1)\n",
        "\n",
        "            sample = self.dataset[index]\n",
        "\n",
        "            x = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[0]]) )).reshape(480,640,3)/255,0,1)\n",
        "            y = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[1]]) )).reshape(480,640,1)/255*self.maxDepth,0,self.maxDepth)\n",
        "            y = DepthNorm(y, maxDepth=self.maxDepth)\n",
        "\n",
        "            batch_x[i] = nyu_resize(x, 480)\n",
        "            batch_y[i] = nyu_resize(y, 240)\n",
        "\n",
        "            if is_apply_policy: batch_x[i], batch_y[i] = self.policy(batch_x[i], batch_y[i])\n",
        "\n",
        "            # DEBUG:\n",
        "            #self.policy.debug_img(batch_x[i], np.clip(DepthNorm(batch_y[i])/maxDepth,0,1), idx, i)\n",
        "        #exit()\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "class NYU_BasicRGBSequence(Sequence):\n",
        "    def __init__(self, data, dataset, batch_size,shape_rgb, shape_depth):\n",
        "        self.data = data\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.N = len(self.dataset)\n",
        "        self.shape_rgb = shape_rgb\n",
        "        self.shape_depth = shape_depth\n",
        "        self.maxDepth = 1000.0\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.N / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x, batch_y = np.zeros( self.shape_rgb ), np.zeros( self.shape_depth )\n",
        "        for i in range(self.batch_size):            \n",
        "            index = min((idx * self.batch_size) + i, self.N-1)\n",
        "\n",
        "            sample = self.dataset[index]\n",
        "\n",
        "            x = np.clip(np.asarray(Image.open( BytesIO(self.data[sample[0]]))).reshape(480,640,3)/255,0,1)\n",
        "            y = np.asarray(Image.open(BytesIO(self.data[sample[1]])), dtype=np.float32).reshape(480,640,1).copy().astype(float) / 10.0\n",
        "            y = DepthNorm(y, maxDepth=self.maxDepth)\n",
        "\n",
        "            batch_x[i] = nyu_resize(x, 480)\n",
        "            batch_y[i] = nyu_resize(y, 240)\n",
        "\n",
        "            # DEBUG:\n",
        "            #self.policy.debug_img(batch_x[i], np.clip(DepthNorm(batch_y[i])/maxDepth,0,1), idx, i)\n",
        "        #exit()\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "def load_test_data(test_data_zip_file='nyu_test.zip'):\n",
        "    print('Loading test data...', end='')\n",
        "    import numpy as np\n",
        "    # from data import extract_zip\n",
        "    data = extract_zip(test_data_zip_file)\n",
        "    from io import BytesIO\n",
        "    rgb = np.load(BytesIO(data['eigen_test_rgb.npy']))\n",
        "    depth = np.load(BytesIO(data['eigen_test_depth.npy']))\n",
        "    crop = np.load(BytesIO(data['eigen_test_crop.npy']))\n",
        "    print('Test data loaded.\\n')\n",
        "    return {'rgb':rgb, 'depth':depth, 'crop':crop}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW62frFGLosG",
        "colab_type": "text"
      },
      "source": [
        "This is callback while training, again all are needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpzZzgsP5TZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "#from utils import DepthNorm, predict, evaluate\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def scale_up(scale, images):\n",
        "    from skimage.transform import resize\n",
        "    scaled = []\n",
        "    \n",
        "    for i in range(len(images)):\n",
        "        img = images[i]\n",
        "        output_shape = (scale * img.shape[0], scale * img.shape[1])\n",
        "        scaled.append( resize(img, output_shape, order=1, preserve_range=True, mode='reflect', anti_aliasing=True ) )\n",
        "\n",
        "    return np.stack(scaled)\n",
        "\n",
        "def predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\n",
        "    # Support multiple RGBs, one RGB image, even grayscale \n",
        "    if len(images.shape) < 3: images = np.stack((images,images,images), axis=2)\n",
        "    if len(images.shape) < 4: images = images.reshape((1, images.shape[0], images.shape[1], images.shape[2]))\n",
        "    # Compute predictions\n",
        "    predictions = model.predict(images, batch_size=batch_size)\n",
        "    # Put in expected range\n",
        "    return np.clip(DepthNorm(predictions, maxDepth=1000), minDepth, maxDepth) / maxDepth\n",
        "\n",
        "def evaluate(model, rgb, depth, crop, batch_size=6, verbose=True):\n",
        "    # Error computaiton based on https://github.com/tinghuiz/SfMLearner\n",
        "    def compute_errors(gt, pred):\n",
        "        thresh = np.maximum((gt / pred), (pred / gt))\n",
        "        \n",
        "        a1 = (thresh < 1.25   ).mean()\n",
        "        a2 = (thresh < 1.25 ** 2).mean()\n",
        "        a3 = (thresh < 1.25 ** 3).mean()\n",
        "\n",
        "        abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
        "\n",
        "        rmse = (gt - pred) ** 2\n",
        "        rmse = np.sqrt(rmse.mean())\n",
        "\n",
        "        log_10 = (np.abs(np.log10(gt)-np.log10(pred))).mean()\n",
        "\n",
        "        return a1, a2, a3, abs_rel, rmse, log_10\n",
        "\n",
        "    depth_scores = np.zeros((6, len(rgb))) # six metrics\n",
        "\n",
        "    bs = batch_size\n",
        "\n",
        "    for i in range(len(rgb)//bs):    \n",
        "        x = rgb[(i)*bs:(i+1)*bs,:,:,:]\n",
        "        \n",
        "        # Compute results\n",
        "        true_y = depth[(i)*bs:(i+1)*bs,:,:]\n",
        "        pred_y = scale_up(2, predict(model, x/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "        \n",
        "        # Test time augmentation: mirror image estimate\n",
        "        pred_y_flip = scale_up(2, predict(model, x[...,::-1,:]/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "\n",
        "        # Crop based on Eigen et al. crop\n",
        "        true_y = true_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y = pred_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y_flip = pred_y_flip[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        \n",
        "        # Compute errors per image in batch\n",
        "        for j in range(len(true_y)):\n",
        "            errors = compute_errors(true_y[j], (0.5 * pred_y[j]) + (0.5 * np.fliplr(pred_y_flip[j])))\n",
        "            \n",
        "            for k in range(len(errors)):\n",
        "                depth_scores[k][(i*bs)+j] = errors[k]\n",
        "\n",
        "    e = depth_scores.mean(axis=1)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
        "        print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))\n",
        "\n",
        "    return e\n",
        "\n",
        "def make_image(tensor):\n",
        "    height, width, channel = tensor.shape\n",
        "    image = Image.fromarray(tensor.astype('uint8'))\n",
        "    output = io.BytesIO()\n",
        "    image.save(output, format='JPEG', quality=90)\n",
        "    image_string = output.getvalue()\n",
        "    output.close()\n",
        "    return tf.Summary.Image(height=height, width=width, colorspace=channel, encoded_image_string=image_string)\n",
        "\n",
        "def get_nyu_callbacks(model, basemodel, train_generator, test_generator, test_set, runPath):\n",
        "    callbacks = []\n",
        "\n",
        "    # Callback: Tensorboard\n",
        "    class LRTensorBoard(keras.callbacks.TensorBoard):\n",
        "        def __init__(self, log_dir):\n",
        "            super().__init__(log_dir=log_dir)\n",
        "\n",
        "            self.num_samples = 6\n",
        "            self.train_idx = np.random.randint(low=0, high=len(train_generator), size=10)\n",
        "            self.test_idx = np.random.randint(low=0, high=len(test_generator), size=10)\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):            \n",
        "            if not test_set == None:\n",
        "                # Samples using current model\n",
        "                import matplotlib.pyplot as plt\n",
        "                from skimage.transform import resize\n",
        "                plasma = plt.get_cmap('plasma')\n",
        "\n",
        "                minDepth, maxDepth = 10, 1000\n",
        "\n",
        "                train_samples = []\n",
        "                test_samples = []\n",
        "\n",
        "                for i in range(self.num_samples):\n",
        "                    x_train, y_train = train_generator.__getitem__(self.train_idx[i], False)\n",
        "                    x_test, y_test = test_generator[self.test_idx[i]]\n",
        "\n",
        "                    x_train, y_train = x_train[0], np.clip(DepthNorm(y_train[0], maxDepth=1000), minDepth, maxDepth) / maxDepth \n",
        "                    x_test, y_test = x_test[0], np.clip(DepthNorm(y_test[0], maxDepth=1000), minDepth, maxDepth) / maxDepth\n",
        "\n",
        "                    h, w = y_train.shape[0], y_train.shape[1]\n",
        "\n",
        "                    rgb_train = resize(x_train, (h,w), preserve_range=True, mode='reflect', anti_aliasing=True)\n",
        "                    rgb_test = resize(x_test, (h,w), preserve_range=True, mode='reflect', anti_aliasing=True)\n",
        "\n",
        "                    gt_train = plasma(y_train[:,:,0])[:,:,:3]\n",
        "                    gt_test = plasma(y_test[:,:,0])[:,:,:3]\n",
        "\n",
        "                    predict_train = plasma(predict(model, x_train, minDepth=minDepth, maxDepth=maxDepth)[0,:,:,0])[:,:,:3]\n",
        "                    predict_test = plasma(predict(model, x_test, minDepth=minDepth, maxDepth=maxDepth)[0,:,:,0])[:,:,:3]\n",
        "\n",
        "                    train_samples.append(np.vstack([rgb_train, gt_train, predict_train]))\n",
        "                    test_samples.append(np.vstack([rgb_test, gt_test, predict_test]))\n",
        "\n",
        "                self.writer.add_summary(tf.Summary(value=[tf.Summary.Value(tag='Train', image=make_image(255 * np.hstack(train_samples)))]), epoch)\n",
        "                self.writer.add_summary(tf.Summary(value=[tf.Summary.Value(tag='Test', image=make_image(255 * np.hstack(test_samples)))]), epoch)\n",
        "                \n",
        "                # Metrics\n",
        "                e = evaluate(model, test_set['rgb'], test_set['depth'], test_set['crop'], batch_size=6, verbose=True)\n",
        "                logs.update({'rel': e[3]})\n",
        "                logs.update({'rms': e[4]})\n",
        "                logs.update({'log10': e[5]})\n",
        "\n",
        "            super().on_epoch_end(epoch, logs)\n",
        "    callbacks.append( LRTensorBoard(log_dir=runPath) )\n",
        "\n",
        "    # Callback: Learning Rate Scheduler\n",
        "    lr_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, min_lr=0.00009, min_delta=1e-2)\n",
        "    callbacks.append( lr_schedule ) # reduce learning rate when stuck\n",
        "\n",
        "    # Callback: save checkpoints\n",
        "    callbacks.append(keras.callbacks.ModelCheckpoint(runPath + '/weights.{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss',\n",
        "        verbose=1, save_best_only=False, save_weights_only=False, mode='min', period=1))\n",
        "\n",
        "    return callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srwf6nTCLvYc",
        "colab_type": "text"
      },
      "source": [
        "A utility to perform bilinear up sampling, needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtWMDxIO2uh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine.topology import Layer, InputSpec\n",
        "import keras.utils.conv_utils as conv_utils\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "class BilinearUpSampling2D(Layer):\n",
        "    def __init__(self, size=(2, 2), data_format=None, **kwargs):\n",
        "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
        "        self.data_format = K.normalize_data_format(data_format)\n",
        "        self.size = conv_utils.normalize_tuple(size, 2, 'size')\n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n",
        "            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n",
        "            return (input_shape[0],\n",
        "                    input_shape[1],\n",
        "                    height,\n",
        "                    width)\n",
        "        elif self.data_format == 'channels_last':\n",
        "            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n",
        "            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n",
        "            return (input_shape[0],\n",
        "                    height,\n",
        "                    width,\n",
        "                    input_shape[3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = K.shape(inputs)\n",
        "        if self.data_format == 'channels_first':\n",
        "            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n",
        "            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n",
        "        elif self.data_format == 'channels_last':\n",
        "            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n",
        "            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n",
        "        \n",
        "        return tf.image.resize_images(inputs, [height, width], method=tf.image.ResizeMethod.BILINEAR, align_corners=True)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'size': self.size, 'data_format': self.data_format}\n",
        "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XT1iJpJL6T8",
        "colab_type": "text"
      },
      "source": [
        "Reduced train file and main file, change the batch size, epoch and learning rate and run this file to start the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp9-QdilJR5l",
        "colab_type": "code",
        "outputId": "7017d144-7778-491a-adfd-f10f5883586e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "import os, sys, glob, time, pathlib\n",
        "\n",
        "from keras import applications\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, InputLayer, Conv2D, Activation, LeakyReLU, Concatenate\n",
        "#from layers import BilinearUpSampling2D\n",
        "from keras.optimizers import Adam\n",
        "#from keras.utils import multi_gpu_model\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# Kerasa / TensorFlow\n",
        "#from utilities import get_nyu_train_test_data, load_test_data, depth_loss_function\n",
        "#from callbacks import get_nyu_callbacks\n",
        "\n",
        "\n",
        "# Define upsampling layer\n",
        "def upproject(base_model, tensor, filters, name, concat_with):\n",
        "    up_i = BilinearUpSampling2D((2, 2), name=name+'_upsampling2d')(tensor)\n",
        "    up_i = Concatenate(name=name+'_concat')([up_i, base_model.get_layer(concat_with).output]) # Skip connection\n",
        "    up_i = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name+'_convA')(up_i)\n",
        "    up_i = LeakyReLU(alpha=0.2)(up_i)\n",
        "    up_i = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name+'_convB')(up_i)\n",
        "    up_i = LeakyReLU(alpha=0.2)(up_i)\n",
        "    return up_i\n",
        "\n",
        "def create_model():\n",
        "    \n",
        "    # Encoder Layers\n",
        "    print('Loading base model (DenseNet)..')\n",
        "    base_model = applications.DenseNet121(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "    \n",
        "    print('Base model loaded.')\n",
        "\n",
        "    # Starting point for decoder\n",
        "    base_model_output_shape = base_model.layers[-1].output.shape\n",
        "    print(\" Output shape is: \", base_model_output_shape)\n",
        "\n",
        "    # Layer freezing?\n",
        "    for layer in base_model.layers: layer.trainable = True\n",
        "    \n",
        "    # Starting half number of decoder filters\n",
        "    \n",
        "    decode_filters = int(int(base_model_output_shape[-1])/2)\n",
        "\n",
        "    decoder = Conv2D(filters=decode_filters, kernel_size=1, padding='same', input_shape=base_model_output_shape, name='conv2')(base_model.output)\n",
        "    decoder = upproject(base_model, decoder, int(decode_filters/2), 'up1', concat_with='pool3_pool')\n",
        "    decoder = upproject(base_model, decoder, int(decode_filters/4), 'up2', concat_with='pool2_pool')\n",
        "    decoder = upproject(base_model, decoder, int(decode_filters/8), 'up3', concat_with='pool1')\n",
        "    decoder = upproject(base_model, decoder, int(decode_filters/16), 'up4', concat_with='conv1/relu')\n",
        "    if False: decoder = upproject(base_model, decoder, int(decode_filters/32), 'up5', concat_with='input_1')\n",
        "    \n",
        "    # Extract depths (final layer)\n",
        "    conv3 = Conv2D(filters=1, kernel_size=3, strides=1, padding='same', name='conv3')(decoder)\n",
        "    \n",
        "    # Create the model\n",
        "    model = Model(inputs=base_model.input, outputs=conv3)\n",
        "    print('Model created.')\n",
        "    \n",
        "    return (base_model,model)\n",
        "\n",
        "def train(batch_size = 5 , epochs = 5, lr = 0.0001):\n",
        "    #batch_size = int(float(args[0]))\n",
        "    #epochs = int(float(args[1])) \n",
        "    #lr = float(args[2])\n",
        "    print(\"batch_size = {0} , epochs = {1}, lr = {2}\".format(batch_size,epochs, lr))\n",
        "\n",
        "    #creates encoder and decoder model\n",
        "    base_model , model = create_model()\n",
        "\n",
        "    train_generator, test_generator = get_nyu_train_test_data( batch_size )\n",
        "\n",
        "    # Training session details\n",
        "    runPath = os.path.join(os.getcwd(),'models',str(int(time.time())))\n",
        "    pathlib.Path(runPath).mkdir(parents=True, exist_ok=True)\n",
        "    print('Output: ' + runPath)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = Adam(lr=lr, amsgrad=True)\n",
        "\n",
        "    model.compile(loss=depth_loss_function, optimizer=optimizer)\n",
        "\n",
        "    print('Ready for training!\\n')\n",
        "\n",
        "    callbacks = []\n",
        "    callbacks = get_nyu_callbacks(model, base_model, train_generator, test_generator, load_test_data(), runPath)\n",
        "\n",
        "    # Start training\n",
        "    model.fit_generator(train_generator, callbacks=None, validation_data=test_generator, epochs=epochs, shuffle=True)\n",
        "\n",
        "    # Save the final trained model:\n",
        "    print('Model Save Began')\n",
        "    base_model.save(runPath + '/model.h5')\n",
        "    print('Model Save Completed')\n",
        "    pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = sys.argv[ 1: ]\n",
        "    if (len(args) <= 0) :\n",
        "        sys.exit( 0 )\n",
        "    \n",
        "    batch_size= 5 #int(args[0]), \n",
        "    epochs= 5 #int(args[1]), \n",
        "    lr= 0.0001 #float(args[2]),\n",
        "    train(batch_size,epochs,lr)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size = 5 , epochs = 5, lr = 0.0001\n",
            "Loading base model (DenseNet)..\n",
            "Base model loaded.\n",
            " Output shape is:  (?, ?, ?, 1024)\n",
            "Model created.\n",
            "Output: /content/models/1575781737\n",
            "Ready for training!\n",
            "\n",
            "Loading test data...Test data loaded.\n",
            "\n",
            "Epoch 1/5\n",
            "35/35 [==============================] - 81s 2s/step - loss: 0.2463 - val_loss: 0.3804\n",
            "Epoch 2/5\n",
            "35/35 [==============================] - 22s 618ms/step - loss: 0.1653 - val_loss: 0.3627\n",
            "Epoch 3/5\n",
            "35/35 [==============================] - 22s 618ms/step - loss: 0.1443 - val_loss: 0.3601\n",
            "Epoch 4/5\n",
            "35/35 [==============================] - 21s 614ms/step - loss: 0.1350 - val_loss: 0.3303\n",
            "Epoch 5/5\n",
            "35/35 [==============================] - 22s 621ms/step - loss: 0.1261 - val_loss: 0.3398\n",
            "Model Save Began\n",
            "Model Save Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTTafL2N_BhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}